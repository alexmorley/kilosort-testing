{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import h5py\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../github/pykilosort')\n",
    "sys.path.append('../github/phylib')\n",
    "from pykilosort import Bunch, run, add_default_handler\n",
    "from pykilosort.utils import memmap_large_array, LargeArrayWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_path = Path('D:\\kilosort-testing\\\\100s_data\\\\p1\\\\imec_385_100s.bin')\n",
    "dir_path = dat_path.parent\n",
    "add_default_handler(level='INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_path = Path('D:\\kilosort-testing\\\\100s_data\\\\matlab_stages')\n",
    "test_path = Path('D:\\kilosort-testing\\\\100s_data\\\\python_stages')\n",
    "dataset_name = 'imec_385_100s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rez(rez_loc):\n",
    "    rez_file = h5py.File(rez_loc)\n",
    "    main_key = list(rez_file.keys())[-1]\n",
    "    rez = Bunch()\n",
    "    for key in rez_file[main_key].keys():\n",
    "        try:\n",
    "            rez[key] = rez_file[main_key][key][()].squeeze()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    for key in rez_file[main_key]['ops'].keys():\n",
    "        try:\n",
    "            rez[key] = rez_file[main_key]['ops'][key][()].squeeze()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    return rez\n",
    "\n",
    "def get_ctx(ctx_loc):\n",
    "    files = os.listdir(ctx_loc)\n",
    "    ctx = Bunch()\n",
    "    for file in files:\n",
    "        if file[-3:] == 'npy':\n",
    "            ctx[file[:-4]] = np.load(ctx_loc / file)\n",
    "    return ctx\n",
    "\n",
    "def transpose_fortran(array):\n",
    "    return np.asfortranarray(array.T)\n",
    "\n",
    "def _save(array, path, name):\n",
    "    np.save(path / name, transpose_fortran(array))\n",
    "    \n",
    "def _save_largearray(array, path, name):\n",
    "    writer = LargeArrayWriter(path / (name + '.dat'), dtype = np.float32, shape = (*array.shape[:-1], -1))\n",
    "    writer.append(np.asfortranarray(array))\n",
    "    writer.close()\n",
    "\n",
    "def setup_dir(path, name):\n",
    "    test_path = path / name / '.kilosort' / dataset_name\n",
    "    if os.path.isdir(test_path):\n",
    "        shutil.rmtree(test_path)\n",
    "    os.makedirs(test_path)\n",
    "    return test_path\n",
    "\n",
    "def test(name, rez, ctx, mapping=None, mapping_axes=None, python_name=None, atol=1e-08):\n",
    "    \n",
    "    if python_name is None:\n",
    "        python_name = name\n",
    "    var_m = np.copy(rez[name]).T\n",
    "    var_p = cp.asnumpy(ctx.intermediate[python_name])\n",
    "    \n",
    "    if mapping_axes is not None:\n",
    "        assert mapping is not None\n",
    "        for i in mapping_axes:\n",
    "            var_m = np.take(var_m, mapping, axis=i)\n",
    "    \n",
    "    return np.allclose(var_m, var_p, atol=atol)\n",
    "\n",
    "def test_abs(name, rez, ctx, mapping=None, mapping_axes=None, python_name=None, atol=1e-08):\n",
    "    \n",
    "    if python_name is None:\n",
    "        python_name = name\n",
    "    var_m = np.abs(np.copy(rez[name]).T)\n",
    "    var_p = np.abs(cp.asnumpy(ctx.intermediate[python_name]))\n",
    "    \n",
    "    if mapping_axes is not None:\n",
    "        assert mapping is not None\n",
    "        for i in mapping_axes:\n",
    "            var_m = np.take(var_m, mapping, axis=i)\n",
    "    \n",
    "    return np.allclose(var_m, var_p, atol=atol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pre_path = setup_dir(test_path, 'test_preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = Bunch()\n",
    "probe.NchanTOT = 385\n",
    "# WARNING: indexing mismatch with MATLAB hence the -1\n",
    "probe.chanMap = np.load(dir_path / 'chanMap.npy').squeeze().astype(np.int64) - 1\n",
    "probe.xc = np.load(dir_path / 'xc.npy').squeeze()\n",
    "probe.yc = np.load(dir_path / 'yc.npy').squeeze()\n",
    "probe.kcoords = np.load(dir_path / 'kcoords.npy').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m22:01:35.620 [I] main:56              Loaded raw data with 385 channels, 3000000 samples.\u001b[0m\n",
      "\u001b[0m22:01:35.622 [I] utils:334            Starting step good_channels.\u001b[0m\n",
      "Finding good channels: 100%|███████████████████████████████████████████████████████████| 46/46 [00:29<00:00,  1.57it/s]\n",
      "\u001b[0m22:02:05.014 [I] preprocess:312       Found 83221 threshold crossings in 100.00 seconds of data.\u001b[0m\n",
      "\u001b[0m22:02:05.015 [I] preprocess:313       Found 81/374 bad channels.\u001b[0m\n",
      "\u001b[0m22:02:05.015 [I] utils:344            Step `good_channels` took 29.39s.\u001b[0m\n",
      "\u001b[0m22:02:05.015 [I] utils:334            Starting step whitening_matrix.\u001b[0m\n",
      "Computing the whitening matrix: 100%|████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.50it/s]\n",
      "\u001b[0m22:02:11.342 [I] preprocess:231       Computed the whitening matrix.\u001b[0m\n",
      "\u001b[0m22:02:11.353 [I] utils:344            Step `whitening_matrix` took 6.34s.\u001b[0m\n",
      "\u001b[0m22:02:11.379 [I] utils:334            Starting step preprocess.\u001b[0m\n",
      "\u001b[0m22:02:11.380 [I] preprocess:349       Loading raw data and applying filters.\u001b[0m\n",
      "Preprocessing: 100%|███████████████████████████████████████████████████████████████████| 46/46 [00:27<00:00,  1.70it/s]\n",
      "\u001b[0m22:02:38.489 [I] utils:344            Step `preprocess` took 27.11s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ctx = run(dat_path, probe=probe, dir_path=test_pre_path.parent.parent, n_channels=385, dtype=np.int16, sample_rate=3e4, stop_after='preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_pre = get_rez(rez_path / 'rez_preprocess.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Wrot', 'xc', 'xcoords', 'yc', 'ycoords', 'AUCsplit', 'GPU', 'NT', 'NTbuff', 'Nbatch', 'Nchan', 'NchanTOT', 'Nfilt', 'Th', 'ThPre', 'chanMap', 'fbinary', 'fproc', 'fs', 'fshigh', 'igood', 'kcoords', 'lam', 'minFR', 'minfr_goodchannels', 'momentum', 'nPCs', 'nSkipCov', 'nfilt_factor', 'nskip', 'nt0', 'nt0min', 'ntbuff', 'reorder', 'sampsToRead', 'scaleproc', 'sigmaMask', 'spkTh', 'tend', 'trange', 'tstart', 'twind', 'useRAM', 'whiteningRange'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rez_pre.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Nbatch', 'igood', 'Wrot', 'proc_path'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir = ctx.intermediate\n",
    "ir.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(ir.igood, rez_pre.igood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61.9022727 , -3.39832827, -4.9992118 , -4.02359851, -4.84960377],\n",
       "       [-3.39830592, 61.04385853, -3.92501876, -4.23253328, -3.43119279],\n",
       "       [-4.99919727, -3.9250236 , 71.22970819, -4.25783359, -5.21818139],\n",
       "       [-4.02358659, -4.23250869, -4.25782129, 77.90967822, -4.6552442 ],\n",
       "       [-4.84959893, -3.4311939 , -5.21820039, -4.65524793, 78.61017585]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rez_pre.Wrot[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62.07098108, -3.42985521, -5.01939981, -4.04189645, -4.87181909],\n",
       "       [-3.42985521, 61.18618388, -3.93719626, -4.26883095, -3.4435032 ],\n",
       "       [-5.01939981, -3.93719626, 71.39750067, -4.26265096, -5.23968566],\n",
       "       [-4.04189645, -4.26883095, -4.26265096, 78.06118443, -4.67152417],\n",
       "       [-4.87181909, -3.4435032 , -5.23968566, -4.67152417, 78.76671274]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir.Wrot[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Batch Reordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cluster_path = setup_dir(test_path, 'test_cluster')\n",
    "\n",
    "rez_preprocess = get_rez(rez_path / 'rez_preprocess.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/kilosort-testing/100s_data/python_stages/test_cluster/.kilosort/imec_385_100s/proc.dat')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = ['igood', 'Wrot']\n",
    "\n",
    "for variable in variables:\n",
    "    _save(rez_preprocess[variable], test_cluster_path, variable)\n",
    "    \n",
    "shutil.copyfile(rez_path / 'temp_wh.dat', test_cluster_path / 'proc.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rez_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = Bunch()\n",
    "probe.NchanTOT = 385\n",
    "# WARNING: indexing mismatch with MATLAB hence the -1\n",
    "probe.chanMap = np.load(dir_path / 'chanMap.npy').squeeze().astype(np.int64) - 1\n",
    "probe.xc = np.load(dir_path / 'xc.npy').squeeze()\n",
    "probe.yc = np.load(dir_path / 'yc.npy').squeeze()\n",
    "probe.kcoords = np.load(dir_path / 'kcoords.npy').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m17:40:37.508 [I] main:56              Loaded raw data with 385 channels, 3000000 samples.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ctx = run(dat_path, probe=probe, dir_path=test_cluster_path.parent.parent, n_channels=385, dtype=np.int16, sample_rate=3e4, stop_after='preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge_path = setup_dir(test_path, 'test_merge')\n",
    "\n",
    "rez_learn = get_rez(rez_path / 'rez_learn.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rez_learn(rez, path):\n",
    "    \n",
    "    variables = ['ccbsort', 'dWU', 'igood', 'iNeigh', 'iNeighPC', 'iorig', 'mu', \n",
    "                 'simScore', 'U', 'U_a', 'U_b', 'UA', 'W', 'W_a', 'W_b',\n",
    "                'WA', 'Wrot', 'wPCA', 'wTEMP']\n",
    "    \n",
    "    for variable in variables:\n",
    "        _save(rez[variable], path, variable)\n",
    "        \n",
    "    _save(rez.ccb, path, 'ccb0')\n",
    "    \n",
    "    _save_largearray(rez.cProj, path, 'fW')\n",
    "    _save_largearray(rez.cProjPC, path, 'fWPC')\n",
    "    \n",
    "    st3 = np.copy(rez.st3)\n",
    "    st3[1,:] = rez.st3[1,:] - 1 # 0-index channels\n",
    "    _save(st3, path, 'st3')\n",
    "    \n",
    "    shutil.copyfile(path / 'fW.dat', path / 'proc.dat') # hack to avoid re-running the pre-processing stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_rez_learn(rez_learn, test_merge_path)\n",
    "del rez_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = Bunch()\n",
    "probe.NchanTOT = 385\n",
    "# WARNING: indexing mismatch with MATLAB hence the -1\n",
    "probe.chanMap = np.load(dir_path / 'chanMap.npy').squeeze().astype(np.int64) - 1\n",
    "probe.xc = np.load(dir_path / 'xc.npy').squeeze()\n",
    "probe.yc = np.load(dir_path / 'yc.npy').squeeze()\n",
    "probe.kcoords = np.load(dir_path / 'kcoords.npy').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m23:25:29.215 [I] main:56              Loaded raw data with 385 channels, 3000000 samples.\u001b[0m\n",
      "\u001b[0m23:25:29.356 [I] utils:334            Starting step merge.\u001b[0m\n",
      "Finding merges:   0%|                                                                          | 0/357 [00:00<?, ?it/s]../github/pykilosort\\pykilosort\\postprocess.py:426: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Q = (Qi / max(Q00, Q01)).min()\n",
      "Finding merges: 100%|███████████████████████████████████████████████████████████████| 357/357 [00:03<00:00, 114.03it/s]\n",
      "\u001b[0m23:25:32.765 [I] utils:344            Step `merge` took 3.41s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ctx = run(dat_path, probe=probe, dir_path=test_merge_path.parent.parent, n_channels=385, dtype=np.int16, sample_rate=3e4, stop_after='merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_merge = get_rez(rez_path / 'rez_merge.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the merge phase it is enough to check that st3 is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st3_matlab = np.copy(rez_merge.st3.T)\n",
    "st3_matlab[:,1] = st3_matlab[:,1] - 1\n",
    "st3_python = cp.asnumpy(ctx.intermediate.st3_m)\n",
    "np.allclose(st3_matlab, st3_python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following clusters were different: []\n"
     ]
    }
   ],
   "source": [
    "ix = np.where(st3_matlab[:,1] - st3_python[:,1] != 0)[0]\n",
    "bad_clusters = np.unique(np.concatenate((st3_python[:,1][ix], st3_matlab[:,1][ix])))\n",
    "print(f'The following clusters were different: {bad_clusters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ctx\n",
    "del rez_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test First Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split1_path = setup_dir(test_path, 'test_split1')\n",
    "rez_merge = get_rez(rez_path / 'rez_merge.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rez_merge(rez, path):\n",
    "   \n",
    "    variables = ['ccbsort', 'dWU', 'igood', 'iNeigh', 'iNeighPC', 'iorig', 'mu', \n",
    "                 'simScore', 'U', 'U_a', 'U_b', 'UA', 'W', 'W_a', 'W_b',\n",
    "                'WA', 'Wrot', 'wPCA', 'wTEMP']\n",
    "    \n",
    "    for variable in variables:\n",
    "        _save(rez[variable], path, variable)\n",
    "        \n",
    "    _save(rez.ccb, path, 'ccb0')\n",
    "    \n",
    "    _save_largearray(rez.cProj, path, 'fW')\n",
    "    _save_largearray(rez.cProjPC, path, 'fWPC')\n",
    "    \n",
    "    st3 = np.copy(rez.st3)\n",
    "    st3[1,:] = rez.st3[1,:] - 1 # 0-index channels\n",
    "    _save(st3, path, 'st3')\n",
    "    _save(st3, path, 'st3_m')\n",
    "    \n",
    "    shutil.copyfile(path / 'fW.dat', path / 'proc.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_rez_merge(rez_merge, test_split1_path)\n",
    "del rez_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = Bunch()\n",
    "probe.NchanTOT = 385\n",
    "# WARNING: indexing mismatch with MATLAB hence the -1\n",
    "probe.chanMap = np.load(dir_path / 'chanMap.npy').squeeze().astype(np.int64) - 1\n",
    "probe.xc = np.load(dir_path / 'xc.npy').squeeze()\n",
    "probe.yc = np.load(dir_path / 'yc.npy').squeeze()\n",
    "probe.kcoords = np.load(dir_path / 'kcoords.npy').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m23:25:36.662 [I] main:56              Loaded raw data with 385 channels, 3000000 samples.\u001b[0m\n",
      "\u001b[0m23:25:36.804 [I] utils:334            Starting step split_1.\u001b[0m\n",
      "\u001b[0m23:25:37.532 [I] postprocess:522      Found 0 splits, checked 0/357 clusters, nccg 0\u001b[0m\n",
      "\u001b[0m23:25:42.824 [I] postprocess:522      Found 4 splits, checked 100/361 clusters, nccg 8\u001b[0m\n",
      "\u001b[0m23:25:47.425 [I] postprocess:522      Found 10 splits, checked 200/367 clusters, nccg 9\u001b[0m\n",
      "\u001b[0m23:25:52.510 [I] postprocess:522      Found 13 splits, checked 300/370 clusters, nccg 14\u001b[0m\n",
      "\u001b[0m23:25:58.552 [I] postprocess:732      Finished splitting. Found 19 splits, checked 376/376 clusters, nccg 19\u001b[0m\n",
      "\u001b[0m23:25:58.741 [I] utils:344            Step `split_1` took 21.94s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ctx = run(dat_path, probe=probe, dir_path=test_split1_path.parent.parent, n_channels=385, dtype=np.int16, sample_rate=3e4, \\\n",
    "          stop_after='split_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_split1 = get_rez(rez_path / 'rez_split1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3_matlab = np.copy(rez_split1.st3.T)\n",
    "st3_matlab[:,1] = st3_matlab[:,1] - 1\n",
    "st3_python = cp.asnumpy(ctx.intermediate.st3_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following clusters were different: [ 44. 173. 195. 246. 357. 358. 359. 360. 361. 362. 363. 365. 369. 371.\n",
      " 372. 373. 374. 375.]\n"
     ]
    }
   ],
   "source": [
    "ix = np.where(st3_matlab[:,1] - st3_python[:,1] != 0)[0]\n",
    "bad_clusters = np.unique(np.concatenate((st3_python[:,1][ix], st3_matlab[:,1][ix])))\n",
    "print(f'The following clusters were different: {bad_clusters}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these differences are just due to labelling, we can try and learn a mapping from the Python clusters to their corresponding Matlab clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping was found\n"
     ]
    }
   ],
   "source": [
    "cluster_mapping = np.zeros((len(bad_clusters), 2), dtype = int)\n",
    "cluster_mapping[:,0] = bad_clusters\n",
    "cluster_mapping[:,1] = -1\n",
    "\n",
    "for i in range(len(bad_clusters)):\n",
    "    ix_p = np.where(st3_python[:,1] == bad_clusters[i])[0]\n",
    "    for j in bad_clusters:\n",
    "        ix_m = np.where(st3_matlab[:,1] == j)[0]\n",
    "        if np.array_equal(ix_p, ix_m):\n",
    "            cluster_mapping[i,1] = j\n",
    "            break\n",
    "\n",
    "mapping_found = False\n",
    "if np.sum(cluster_mapping[:,1] == -1):\n",
    "    print(f\"No mapping found as the following Python clusters can't be matched:\" \\\n",
    "        f\"{cluster_mapping[:,0][np.where(cluster_mapping[:,1] == 0)[0]]}\")\n",
    "elif np.max(st3_matlab[:,1]) != np.max(st3_python[:,1]):\n",
    "    print(\"Some Matlab clusters had no corresponding Python match\")\n",
    "else:\n",
    "    mapping = np.arange(np.max(st3_python[:,1] + 1), dtype=int)\n",
    "    for i in range(cluster_mapping.shape[0]):\n",
    "        mapping[cluster_mapping[i,0]] = cluster_mapping[i,1]\n",
    "    mapping_found = True\n",
    "    print(\"Mapping was found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu matches: True\n",
      "simScore matches: True\n",
      "isplit matches: True\n",
      "iNeighPC matches: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"mu matches: {test('mu', rez_split1, ctx, mapping, [0], 'mu_s')}\")\n",
    "print(f\"simScore matches: {test('simScore', rez_split1, ctx, mapping, [0,1], 'simScore_s')}\")\n",
    "print(f\"isplit matches: {test('isplit', rez_split1, ctx, mapping, [0,1])}\")\n",
    "\n",
    "print(f\"iNeighPC matches: {np.allclose(cp.asnumpy(ctx.intermediate.iNeighPC_s.T), (rez_split1.iNeighPC-1)[mapping])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD components only match up to an arbitrary sign so we compare absolute values and also use a higher tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W matches: True\n",
      "U matches: True\n",
      "Wphy matches: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"W matches: {test_abs('W', rez_split1, ctx, mapping, [1], 'W_s', atol=1e-05)}\")\n",
    "print(f\"U matches: {test_abs('U', rez_split1, ctx, mapping, [1], 'U_s', atol=1e-05)}\")\n",
    "print(f\"Wphy matches: {test_abs('Wphy', rez_split1, ctx, mapping, [1], atol=1e-05)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iNeigh stores the nearest 32 neighbours for each template. Due to rounding errors this may not always match so we check to see how many nearest neighbours match. iList does exactly the same (repeated variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nearest neighbours that match in iNeigh: 21/32\n",
      "Number of nearest neighbours that match in iList: 21/32\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of nearest neighbours that match in iNeigh: \\\n",
    "{np.min(np.where((rez_split1.iNeigh-1)[mapping] != mapping[cp.asnumpy(ctx.intermediate.iNeigh_s.T)])[1])}/32\")\n",
    "print(f\"Number of nearest neighbours that match in iList: \\\n",
    "{np.min(np.where((rez_split1.iList-1)[mapping] != mapping[cp.asnumpy(ctx.intermediate.iList.T)])[1])}/32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ctx\n",
    "del rez_split1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Second Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split2_path = setup_dir(test_path, 'test_split2')\n",
    "rez_split1 = get_rez(rez_path / 'rez_split1.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rez_split1(rez, path):\n",
    "   \n",
    "    variables = ['ccbsort', 'dWU', 'igood', 'iList', 'iNeigh', 'iNeighPC', 'iorig', 'isplit', 'mu', \n",
    "                 'simScore', 'U', 'U_a', 'U_b', 'UA', 'W', 'W_a', 'W_b',\n",
    "                'WA', 'Wrot', 'Wphy', 'wPCA', 'wTEMP']\n",
    "    \n",
    "    for variable in variables:\n",
    "        _save(rez[variable], path, variable)\n",
    "        \n",
    "    _save(rez.ccb, path, 'ccb0')\n",
    "    \n",
    "    _save_largearray(rez.cProj, path, 'fW')\n",
    "    _save_largearray(rez.cProjPC, path, 'fWPC')\n",
    "    \n",
    "    st3 = np.copy(rez.st3)\n",
    "    st3[1,:] = rez.st3[1,:] - 1 # 0-index channels\n",
    "    _save(st3, path, 'st3')\n",
    "    _save(st3, path, 'st3_m')\n",
    "    _save(st3, path, 'st3_s1')\n",
    "    \n",
    "    _save(rez.iNeigh, path, 'iNeigh_s')\n",
    "    _save(rez.iNeighPC, path, 'iNeighPC_s')\n",
    "    _save(rez.mu, path, 'mu_s')\n",
    "    _save(rez.simScore, path, 'simScore_s')\n",
    "    _save(rez.U, path, 'U_s')\n",
    "    _save(rez.W, path, 'W_s')\n",
    "    \n",
    "    shutil.copyfile(path / 'fW.dat', path / 'proc.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_rez_split1(rez_split1, test_split2_path)\n",
    "del rez_split1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = Bunch()\n",
    "probe.NchanTOT = 385\n",
    "# WARNING: indexing mismatch with MATLAB hence the -1\n",
    "probe.chanMap = np.load(dir_path / 'chanMap.npy').squeeze().astype(np.int64) - 1\n",
    "probe.xc = np.load(dir_path / 'xc.npy').squeeze()\n",
    "probe.yc = np.load(dir_path / 'yc.npy').squeeze()\n",
    "probe.kcoords = np.load(dir_path / 'kcoords.npy').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m23:26:02.808 [I] main:56              Loaded raw data with 385 channels, 3000000 samples.\u001b[0m\n",
      "\u001b[0m23:26:03.043 [I] utils:334            Starting step split_2.\u001b[0m\n",
      "\u001b[0m23:26:03.308 [I] postprocess:522      Found 0 splits, checked 0/376 clusters, nccg 0\u001b[0m\n",
      "\u001b[0m23:26:07.380 [I] postprocess:522      Found 1 splits, checked 100/377 clusters, nccg 9\u001b[0m\n",
      "\u001b[0m23:26:10.468 [I] postprocess:522      Found 1 splits, checked 200/377 clusters, nccg 10\u001b[0m\n",
      "\u001b[0m23:26:14.338 [I] postprocess:522      Found 1 splits, checked 300/377 clusters, nccg 14\u001b[0m\n",
      "\u001b[0m23:26:19.683 [I] postprocess:732      Finished splitting. Found 3 splits, checked 379/379 clusters, nccg 20\u001b[0m\n",
      "\u001b[0m23:26:19.844 [I] utils:344            Step `split_2` took 16.80s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ctx = run(dat_path, probe=probe, dir_path=test_split2_path.parent.parent, n_channels=385, dtype=np.int16, sample_rate=3e4, \\\n",
    "          stop_after='split_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_split2 = get_rez(rez_path / 'rez_split2.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "st3_matlab = np.copy(rez_split2.st3.T)\n",
    "st3_matlab[:,1] = st3_matlab[:,1] - 1\n",
    "st3_python = cp.asnumpy(ctx.intermediate.st3_s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following clusters were different: []\n"
     ]
    }
   ],
   "source": [
    "ix = np.where(st3_matlab[:,1] - st3_python[:,1] != 0)[0]\n",
    "bad_clusters = np.unique(np.concatenate((st3_python[:,1][ix], st3_matlab[:,1][ix])))\n",
    "print(f'The following clusters were different: {bad_clusters}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these differences are just due to labelling, we can try and learn a mapping from the Python clusters to their corresponding Matlab clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping was found\n"
     ]
    }
   ],
   "source": [
    "cluster_mapping = np.zeros((len(bad_clusters), 2), dtype = int)\n",
    "cluster_mapping[:,0] = bad_clusters\n",
    "cluster_mapping[:,1] = -1\n",
    "\n",
    "for i in range(len(bad_clusters)):\n",
    "    ix_p = np.where(st3_python[:,1] == bad_clusters[i])[0]\n",
    "    for j in bad_clusters:\n",
    "        ix_m = np.where(st3_matlab[:,1] == j)[0]\n",
    "        if np.array_equal(ix_p, ix_m):\n",
    "            cluster_mapping[i,1] = j\n",
    "            break\n",
    "\n",
    "mapping_found = False\n",
    "if np.sum(cluster_mapping[:,1] == -1) > 0:\n",
    "    print(f\"No mapping found as the following Python clusters can't be matched:\" \\\n",
    "        f\"{cluster_mapping[:,0][np.where(cluster_mapping[:,1] == 0)[0]]}\")\n",
    "elif np.max(st3_matlab[:,1]) != np.max(st3_python[:,1]):\n",
    "    print(\"Some Matlab clusters had no corresponding Python match\")\n",
    "else:\n",
    "    mapping = np.arange(np.max(st3_python[:,1] + 1), dtype=int)\n",
    "    for i in range(cluster_mapping.shape[0]):\n",
    "        mapping[cluster_mapping[i,0]] = cluster_mapping[i,1]\n",
    "    mapping_found = True\n",
    "    print(\"Mapping was found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu matches: True\n",
      "simScore matches: True\n",
      "isplit matches: True\n",
      "iNeighPC matches: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"mu matches: {test('mu', rez_split2, ctx, mapping, [0], 'mu_s')}\")\n",
    "print(f\"simScore matches: {test('simScore', rez_split2, ctx, mapping, [0,1], 'simScore_s')}\")\n",
    "print(f\"isplit matches: {test('isplit', rez_split2, ctx, mapping, [0,1])}\")\n",
    "\n",
    "print(f\"iNeighPC matches: {np.allclose(cp.asnumpy(ctx.intermediate.iNeighPC_s.T), rez_split2.iNeighPC - 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD components only match up to an arbitrary sign so we compare absolute values and also use a higher tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W matches: True\n",
      "U matches: True\n",
      "Wphy matches: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"W matches: {test_abs('W', rez_split2, ctx, mapping, [1], 'W_s', atol=1e-05)}\")\n",
    "print(f\"U matches: {test_abs('U', rez_split2, ctx, mapping, [1], 'U_s', atol=1e-05)}\")\n",
    "print(f\"Wphy matches: {test_abs('Wphy', rez_split2, ctx, mapping, [1], atol=1e-05)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iNeigh stores the nearest 32 neighbours for each template. Due to rounding errors this may not always match so we check to see how many nearest neighbours match. iList does exactly the same (repeated variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nearest neighbours that match in iNeigh: 21/32\n",
      "Number of nearest neighbours that match in iList: 21/32\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of nearest neighbours that match in iNeigh: \\\n",
    "{np.min(np.where((rez_split2.iNeigh-1)[mapping] != mapping[cp.asnumpy(ctx.intermediate.iNeigh_s.T)])[1])}/32\")\n",
    "print(f\"Number of nearest neighbours that match in iList: \\\n",
    "{np.min(np.where((rez_split2.iList-1)[mapping] != mapping[cp.asnumpy(ctx.intermediate.iList.T)])[1])}/32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ctx\n",
    "del rez_split2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cutoff_path = setup_dir(test_path, 'test_cutoff')\n",
    "rez_split2 = get_rez(rez_path / 'rez_split2.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rez_split2(rez, path):\n",
    "   \n",
    "    variables = ['ccbsort', 'dWU', 'igood', 'iList', 'iNeigh', 'iNeighPC', 'iorig', 'isplit', 'mu', \n",
    "                 'simScore', 'U', 'U_a', 'U_b', 'UA', 'W', 'W_a', 'W_b',\n",
    "                'WA', 'Wrot', 'Wphy', 'wPCA', 'wTEMP']\n",
    "    \n",
    "    for variable in variables:\n",
    "        _save(rez[variable], path, variable)\n",
    "        \n",
    "    _save(rez.ccb, path, 'ccb0')\n",
    "    \n",
    "    _save_largearray(rez.cProj, path, 'fW')\n",
    "    _save_largearray(rez.cProjPC, path, 'fWPC')\n",
    "    \n",
    "    st3 = np.copy(rez.st3)\n",
    "    st3[1,:] = rez.st3[1,:] - 1 # 0-index channels\n",
    "    _save(st3, path, 'st3')\n",
    "    _save(st3, path, 'st3_m')\n",
    "    _save(st3, path, 'st3_s1')\n",
    "    _save(st3, path, 'st3_s0')\n",
    "    \n",
    "    _save(rez.iNeigh, path, 'iNeigh_s')\n",
    "    _save(rez.iNeighPC, path, 'iNeighPC_s')\n",
    "    _save(rez.mu, path, 'mu_s')\n",
    "    _save(rez.simScore, path, 'simScore_s')\n",
    "    _save(rez.U, path, 'U_s')\n",
    "    _save(rez.W, path, 'W_s')\n",
    "    \n",
    "    shutil.copyfile(path / 'fW.dat', path / 'proc.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_rez_split2(rez_split2, test_cutoff_path)\n",
    "del rez_split2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = Bunch()\n",
    "probe.NchanTOT = 385\n",
    "# WARNING: indexing mismatch with MATLAB hence the -1\n",
    "probe.chanMap = np.load(dir_path / 'chanMap.npy').squeeze().astype(np.int64) - 1\n",
    "probe.xc = np.load(dir_path / 'xc.npy').squeeze()\n",
    "probe.yc = np.load(dir_path / 'yc.npy').squeeze()\n",
    "probe.kcoords = np.load(dir_path / 'kcoords.npy').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m23:26:23.964 [I] main:56              Loaded raw data with 385 channels, 3000000 samples.\u001b[0m\n",
      "\u001b[0m23:26:24.207 [I] utils:334            Starting step cutoff.\u001b[0m\n",
      "Setting cutoff: 100%|███████████████████████████████████████████████████████████████| 379/379 [00:02<00:00, 186.19it/s]\n",
      "\u001b[0m23:26:26.249 [I] utils:344            Step `cutoff` took 2.04s.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ctx = run(dat_path, probe=probe, dir_path=test_cutoff_path.parent.parent, n_channels=385, dtype=np.int16, sample_rate=3e4, \\\n",
    "          stop_after='cutoff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez_cutoff = get_rez(rez_path / 'rez_cutoff.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ths matches: True\n",
      "good matches: True\n",
      "est_contam_rate matches: True\n",
      "st3 matches: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ths matches: {np.allclose(rez_cutoff.Ths, ctx.intermediate.Ths)}\")\n",
    "print(f\"good matches: {np.allclose(rez_cutoff.good, ctx.intermediate.good)}\")\n",
    "print(f\"est_contam_rate matches: {np.allclose(rez_cutoff.est_contam_rate, ctx.intermediate.est_contam_rate)}\")\n",
    "\n",
    "st3_matlab = np.copy(rez_cutoff.st3.T)\n",
    "st3_matlab[:,1] = st3_matlab[:,1] - 1\n",
    "st3_python = cp.asnumpy(ctx.intermediate.st3_c)\n",
    "print(f\"st3 matches: {np.allclose(st3_python, st3_matlab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ctx\n",
    "del rez_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
